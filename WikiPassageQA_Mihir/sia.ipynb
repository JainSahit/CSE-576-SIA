{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sia.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7e733a7ec764add809df29c8549d5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b49fd28b984a40e0aaaf66a9bb056078",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6a6793416ba4fc3919d77d220396059",
              "IPY_MODEL_42b47dd1ef664f6e821bfd31291692a8"
            ]
          }
        },
        "b49fd28b984a40e0aaaf66a9bb056078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6a6793416ba4fc3919d77d220396059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae764d13dc1b469bae063a904cf6847f",
            "_dom_classes": [],
            "description": "Epochs: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd969efaf7bf4d8a975218e159ca5906"
          }
        },
        "42b47dd1ef664f6e821bfd31291692a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_744b875b16b04ba4a07777a86571447c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [4:56:54&lt;00:00, 1781.48s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b560ef75e9304283941617775d9505ee"
          }
        },
        "ae764d13dc1b469bae063a904cf6847f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd969efaf7bf4d8a975218e159ca5906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "744b875b16b04ba4a07777a86571447c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b560ef75e9304283941617775d9505ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV0WPAzb8WUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a3be24-15bb-4a29-a253-b894c1bf2542"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-ZgdlghL35-"
      },
      "source": [
        "GPU and available memory check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BdD133t8_yE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff80088-cba1-4f08-a3c3-02f68c4c9157"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.3 GB  |     Proc size: 111.7 MB\n",
            "GPU RAM Free: 16130MB | Used: 0MB | Util   0% | Total     16130MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxI_bH3nMWwU"
      },
      "source": [
        "Transformers for general purpose NLP models\n",
        "\n",
        "Unidecode for ASCII translation of Unicode text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ProxRZG19EvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffafe549-8d2e-4539-a552-07004214a518"
      },
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaR1kCaX9H1H"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udaVulil9Jo6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "import unidecode\n",
        "import re\n",
        "import logging\n",
        "from tqdm.notebook import tnrange\n",
        "import glob\n",
        "import json\n",
        "\n",
        "#For ploting results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# DL Libraries\n",
        "from transformers import BertModel, AdamW, BertTokenizer, BertConfig, RobertaTokenizer, RobertaModel\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4OvOrtF9MKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181a47c3-60a2-476f-db2e-595223e7cde7"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(\"device: {} n_gpu: {}\".format(device, n_gpu)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda n_gpu: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL5xOuWM9OKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07843fe7-d3ee-4049-9ce2-674281cf17a3"
      },
      "source": [
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "print(logger)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Logger __main__ (INFO)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-51uiEKJ9SGG"
      },
      "source": [
        "#Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPnAk7bgMtiI"
      },
      "source": [
        "Function to tokenize input dataframe (Query, Sentence, Label) and return tensorDatset with corresponding input_id, attention_masks and labels as a PyTorch dataloader. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9ebvwdy9bPc"
      },
      "source": [
        "def create_dataloader(tokenizer, df):\n",
        "    input_ids= list()\n",
        "    attention_masks= list()\n",
        "\n",
        "    print(\"Shape: {}\".format(df.shape))\n",
        "\n",
        "    special_sentences_1 = [sentence for i, sentence in enumerate(df.question)]\n",
        "    special_sentences_2 = [\" [SEP] \" + str(sentence) for i, sentence in enumerate(df.answer)]\n",
        "    special_sentences = [i + j for i, j in zip(special_sentences_1, special_sentences_2)]\n",
        "\n",
        "    for sentence in special_sentences:\n",
        "      encoded_text = tokenizer.encode_plus(sentence, max_length=512, add_special_tokens=True, return_token_type_ids=False, \n",
        "                                       padding='max_length', return_attention_mask=True, truncation=True)\n",
        "      input_ids.append(encoded_text['input_ids'])\n",
        "      attention_masks.append(encoded_text['attention_mask'])\n",
        "\n",
        "    inputs = torch.tensor(input_ids).to(device)\n",
        "    masks = torch.tensor(attention_masks).to(device)\n",
        "    gold_labels = torch.tensor(df.sia_score.tolist()).to(device)\n",
        "  \n",
        "    data = TensorDataset(inputs, masks, gold_labels)\n",
        "    sampler = RandomSampler(data)\n",
        "    dataloader = DataLoader(data, sampler=sampler, batch_size=8)\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4aFg_k79ihP"
      },
      "source": [
        "load_data= '/content/drive/My Drive/Mihir/work/man_mihir_project/data/sia_data'\n",
        "\n",
        "train_df= pd.read_csv(join(load_data,'train_sia_data.csv'))\n",
        "dev_df= pd.read_csv(join(load_data,'dev_sia_data.csv'))\n",
        "test_df= pd.read_csv(join(load_data,'test_sia_data.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hme5lMASO0ya"
      },
      "source": [
        "Loading pretrained 'roberta-base' tokenizer and creating dataloader for train & test dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGwP2HAe-XOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb42180e-1c79-4c9d-d9bd-d372c5184208"
      },
      "source": [
        "#Dataloaders\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "train_dataloader= create_dataloader(tokenizer, train_df)\n",
        "dev_dataloader= create_dataloader(tokenizer, dev_df)\n",
        "test_dataloader= create_dataloader(tokenizer, test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (51012, 3)\n",
            "Shape: (6111, 3)\n",
            "Shape: (6312, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXtqwzjtHMM_"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGD23NFQOe2"
      },
      "source": [
        "Model: 'roberta-base' with a Linear layer on top to generate SIA scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "objCF2naHNeR"
      },
      "source": [
        "#Class for Regression\n",
        "class Regressor(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Regressor, self).__init__()\n",
        "    self.bert = RobertaModel.from_pretrained('roberta-base')\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    output, pooler_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    score= self.out(pooler_out)\n",
        "    return score\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0lUjY7RPbwt"
      },
      "source": [
        "Model Initialization with:\n",
        "\n",
        "* 10 epochs\n",
        "\n",
        "* 'AdamW' optimizer\n",
        "\n",
        "* Mean Squared Error (MSE) Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2nHjhrpHV3b"
      },
      "source": [
        "#Model Intialization\n",
        "\n",
        "epochs=10\n",
        "\n",
        "#Load Model\n",
        "model= Regressor()\n",
        "model.to(device)\n",
        "\n",
        "# Prepare optimizer\n",
        "optimizer = AdamW(model.parameters(),lr=2e-5)\n",
        "\n",
        "#Loss Function\n",
        "mse_loss= nn.MSELoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ2Y6ATjHdFL"
      },
      "source": [
        "#Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDWWMBZtQp0N"
      },
      "source": [
        "Creating output directory:\n",
        "\n",
        "model path: '/content/drive/My Drive/project_nlp/sia_experiment/model1'\n",
        "\n",
        "result path: '/content/drive/My Drive/project_nlp/sia_experiment/results1'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XorrsE4iHfNz"
      },
      "source": [
        "output_dir= '/content/drive/My Drive/Mihir/work/man_mihir_project/sia_experiment/model'\n",
        "output_result= '/content/drive/My Drive/Mihir/work/man_mihir_project/sia_experiment/results'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "if not os.path.exists(output_result):\n",
        "  os.makedirs(output_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_93zgQbRRmm"
      },
      "source": [
        "Model training followed by model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igAHY2yyH13H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f7e733a7ec764add809df29c8549d5ce",
            "b49fd28b984a40e0aaaf66a9bb056078",
            "e6a6793416ba4fc3919d77d220396059",
            "42b47dd1ef664f6e821bfd31291692a8",
            "ae764d13dc1b469bae063a904cf6847f",
            "bd969efaf7bf4d8a975218e159ca5906",
            "744b875b16b04ba4a07777a86571447c",
            "b560ef75e9304283941617775d9505ee"
          ]
        },
        "outputId": "5c87e5fb-8220-4899-e8ee-0928c16ef3e4"
      },
      "source": [
        "for iteration in tnrange(epochs, desc='Epochs'):\n",
        "  model.train()\n",
        "  logger.info(\"Running for iteration: {}\".format(iteration+1))\n",
        "\n",
        "  training_loss, training_steps=0,0\n",
        "  true_labels, predicted_labels= list(), list()\n",
        "  \n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    ip_ids, masks, gold_labels= batch\n",
        "    score = model(ip_ids, attention_mask=masks)\n",
        "    score = score.squeeze(1)\n",
        "    loss= mse_loss(score, gold_labels.float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    training_loss+=loss.item()\n",
        "    training_steps+=1\n",
        "\n",
        "    true_labels.extend(gold_labels.cpu().numpy())\n",
        "    predicted_labels.extend(score.detach().cpu().numpy())\n",
        "  \n",
        "  training_loss_for_epoch= training_loss/training_steps\n",
        "  pcc= pearsonr(true_labels, predicted_labels)\n",
        "  rmse= mean_squared_error(true_labels, predicted_labels, squared=False)\n",
        "  result = {'loss': training_loss_for_epoch, 'PCC': pcc[0], 'RMSE':rmse}\n",
        "  print(result)\n",
        "\n",
        "  model_to_save = model.bert.module if hasattr(model.bert, 'module') else model.bert\n",
        "  model_to_save.save_pretrained(output_dir)\n",
        "\n",
        "  torch.save(model.out.state_dict(), join(output_dir, 'model_state.bin'))\n",
        "\n",
        "  #Validation\n",
        "  print(\"Running validation for epoch: {}\".format(iteration+1))\n",
        "\n",
        "  true_labels, predicted_labels= list(), list()\n",
        "  val_loss, val_steps=0,0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for step, batch in enumerate(dev_dataloader):\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      ip_ids, masks, gold_labels= batch\n",
        "      score = model(ip_ids, attention_mask=masks)\n",
        "      score = score.squeeze(1)\n",
        "      loss= mse_loss(score, gold_labels.float())\n",
        "      val_loss+=loss.item()\n",
        "      val_steps+=1\n",
        "\n",
        "      true_labels.extend(gold_labels.cpu().numpy())\n",
        "      predicted_labels.extend(score.detach().cpu().numpy())\n",
        "  \n",
        "  val_loss_for_epoch= val_loss/val_steps\n",
        "  pcc= pearsonr(true_labels, predicted_labels)\n",
        "  rmse= mean_squared_error(true_labels, predicted_labels, squared=False)\n",
        "  test_report= {'loss': val_loss_for_epoch, 'PCC': pcc[0], 'RMSE':str(rmse)}\n",
        "  print(test_report)\n",
        "\n",
        "  #Testing\n",
        "  print(\"Running evaluation for epoch: {}\".format(iteration+1))\n",
        "\n",
        "  true_labels, predicted_labels= list(), list()\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      ip_ids, masks, gold_labels= batch\n",
        "      score = model(ip_ids, attention_mask=masks)\n",
        "      score = score.squeeze(1)\n",
        "\n",
        "      true_labels.extend(gold_labels.cpu().numpy())\n",
        "      predicted_labels.extend(score.detach().cpu().numpy())\n",
        "  \n",
        "  pcc= pearsonr(true_labels, predicted_labels)\n",
        "  rmse= mean_squared_error(true_labels, predicted_labels, squared=False)\n",
        "  test_report= {'PCC': pcc[0], 'RMSE':str(rmse)}\n",
        "  print(test_report)\n",
        "\n",
        "  with open(join(output_result, 'result_'+str(iteration+1)+'.json'), 'w') as fp:\n",
        "    json.dump(test_report, fp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7e733a7ec764add809df29c8549d5ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=10.0, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 00:52:08 - INFO - __main__ -   Running for iteration: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'loss': 0.5266859620644233, 'PCC': 0.6040618884444051, 'RMSE': 0.7257527}\n",
            "Running validation for epoch: 1\n",
            "{'loss': 0.44674821646094165, 'PCC': 0.5872597255492085, 'RMSE': '0.6684408'}\n",
            "Running evaluation for epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 01:21:50 - INFO - __main__ -   Running for iteration: 2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.592949521688731, 'RMSE': '0.68295664'}\n",
            "{'loss': 0.3708119323374626, 'PCC': 0.7429421213960177, 'RMSE': 0.6089458}\n",
            "Running validation for epoch: 2\n",
            "{'loss': 0.42568886601878086, 'PCC': 0.5913124039912669, 'RMSE': '0.65247697'}\n",
            "Running evaluation for epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 01:51:31 - INFO - __main__ -   Running for iteration: 3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.6126418709092778, 'RMSE': '0.6523529'}\n",
            "{'loss': 0.30547364057118087, 'PCC': 0.7942870213236641, 'RMSE': 0.55265903}\n",
            "Running validation for epoch: 3\n",
            "{'loss': 0.4825591450625377, 'PCC': 0.5832100631178629, 'RMSE': '0.69468254'}\n",
            "Running evaluation for epoch: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 02:21:13 - INFO - __main__ -   Running for iteration: 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.5912090434949465, 'RMSE': '0.7045721'}\n",
            "{'loss': 0.2626739875671245, 'PCC': 0.8261565396289542, 'RMSE': 0.51253074}\n",
            "Running validation for epoch: 4\n",
            "{'loss': 0.4720981094488845, 'PCC': 0.5765449539810705, 'RMSE': '0.68713367'}\n",
            "Running evaluation for epoch: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 02:50:52 - INFO - __main__ -   Running for iteration: 5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.5735503591775546, 'RMSE': '0.71010953'}\n",
            "{'loss': 0.22121057712825087, 'PCC': 0.8559527235805487, 'RMSE': 0.47032884}\n",
            "Running validation for epoch: 5\n",
            "{'loss': 0.44745645154735647, 'PCC': 0.5886052882870334, 'RMSE': '0.66895795'}\n",
            "Running evaluation for epoch: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 03:20:33 - INFO - __main__ -   Running for iteration: 6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.5913106390632916, 'RMSE': '0.6895179'}\n",
            "{'loss': 0.19220350798614053, 'PCC': 0.8761858711654654, 'RMSE': 0.4384154}\n",
            "Running validation for epoch: 6\n",
            "{'loss': 0.507854274976316, 'PCC': 0.5794808926938192, 'RMSE': '0.7126828'}\n",
            "Running evaluation for epoch: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 03:50:13 - INFO - __main__ -   Running for iteration: 7\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.5699463893014216, 'RMSE': '0.7450327'}\n",
            "{'loss': 0.164368638072929, 'PCC': 0.895173403431865, 'RMSE': 0.4054337}\n",
            "Running validation for epoch: 7\n",
            "{'loss': 0.5093861876874772, 'PCC': 0.5819130517244827, 'RMSE': '0.7137616'}\n",
            "Running evaluation for epoch: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 04:19:55 - INFO - __main__ -   Running for iteration: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.5803771199860133, 'RMSE': '0.7331443'}\n",
            "{'loss': 0.14269512340756357, 'PCC': 0.9096889489739736, 'RMSE': 0.3777525}\n",
            "Running validation for epoch: 8\n",
            "{'loss': 0.5032455213367939, 'PCC': 0.5778445675264673, 'RMSE': '0.70934534'}\n",
            "Running evaluation for epoch: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 04:49:36 - INFO - __main__ -   Running for iteration: 9\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.5772541905671027, 'RMSE': '0.73568857'}\n",
            "{'loss': 0.13165219620544763, 'PCC': 0.916998482720494, 'RMSE': 0.36283407}\n",
            "Running validation for epoch: 9\n",
            "{'loss': 0.5117116411660276, 'PCC': 0.5725776146692011, 'RMSE': '0.7153465'}\n",
            "Running evaluation for epoch: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/20/2020 05:19:20 - INFO - __main__ -   Running for iteration: 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'PCC': 0.5729123339037223, 'RMSE': '0.7356315'}\n",
            "{'loss': 0.11269743514643164, 'PCC': 0.9294081509450887, 'RMSE': 0.33569396}\n",
            "Running validation for epoch: 10\n",
            "{'loss': 0.5233996129224164, 'PCC': 0.5790363937733175, 'RMSE': '0.7234673'}\n",
            "Running evaluation for epoch: 10\n",
            "{'PCC': 0.582014837780855, 'RMSE': '0.7417391'}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}